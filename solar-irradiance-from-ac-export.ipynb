{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b4f091",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Solar Irradiance From AC Export\n",
    "\n",
    "A Jupyter Notebook that does it's best to model and construct a historical solar irradiance time series from solar panel park's historical AC export data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb98ad",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5f3b9",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "\n",
    "# Standard Library Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd074bad",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 1.2 Configuration\n",
    "\n",
    "This project uses a two-step configuration process:\n",
    "\n",
    "1.  **Path Definition (`.env`):** This file defines the project's physical location (`PROJECT_ROOT`) and the name of the configuration file. This separation ensures the notebook is portable across different machines and environments.\n",
    "2.  **Parameter Definition (`config.yml`):** This file contains the physical and electrical parameters of your solar park(s), including sensitive information like GPS coordinates and detailed system specifications.\n",
    "\n",
    "**To get started:**\n",
    "\n",
    "1.  **Configure Paths:** Copy the template file `.env.example` to a new file named `.env`. Open `.env` and set the absolute path for the `PROJECT_ROOT` variable.\n",
    "2.  **Configure Parks:** Copy the example configuration file `config.example.yml` to `config.yml`. Open `config.yml` and replace the placeholder values with the details of your solar installation.\n",
    "\n",
    "The cell below loads the environment variables, resolves the final configuration path, and sets up the plotting environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cf6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define paths using environment variables\n",
    "PROJECT_ROOT_STR = os.getenv(\"PROJECT_ROOT\")\n",
    "CONFIG_FILENAME = os.getenv(\"CONFIG_FILENAME\", \"config.yml\")  # Fallback to config.yml\n",
    "PRODUCTION_AND_PRICE_FILE_PATH = os.getenv(\n",
    "    \"PRODUCTION_AND_PRICE_FILE_PATH\",\n",
    "    \"/home/user/solar-irradiance-from-ac-export/production.csv\",\n",
    ")\n",
    "WEATHER_FILE_PATH = os.getenv(\n",
    "    \"WEATHER_FILE_PATH\", \"/home/user/solar-irradiance-from-ac-export/weather.csv\"\n",
    ")\n",
    "\n",
    "if not PROJECT_ROOT_STR:\n",
    "    # If PROJECT_ROOT is not set in .env, assume the current working directory\n",
    "    PROJECT_ROOT_STR = os.getcwd()\n",
    "    print(\n",
    "        f\"‚ö†Ô∏è WARNING: PROJECT_ROOT not set in .env. Using current directory: {PROJECT_ROOT_STR}\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT_STR)\n",
    "CONFIG_PATH = PROJECT_ROOT / CONFIG_FILENAME\n",
    "\n",
    "print(f\"Project Root defined as: {PROJECT_ROOT}\")\n",
    "print(f\"Configuration file path: {CONFIG_PATH}\")\n",
    "\n",
    "try:\n",
    "    with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # Extract park configurations\n",
    "    PARK_CONFIGS = config.get(\"parks\", {})\n",
    "\n",
    "    if not PARK_CONFIGS:\n",
    "        raise ValueError(\n",
    "            \"No parks defined under the 'parks' key in the configuration file.\"\n",
    "        )\n",
    "\n",
    "    # Create a list of park names for easy iteration later\n",
    "    PARK_NAMES = list(PARK_CONFIGS.keys())\n",
    "\n",
    "    # --- Load and Validate Target Park for Analysis ---\n",
    "    TARGET_PARK_NAME = os.getenv(\"TARGET_PARK_NAME\")\n",
    "\n",
    "    if not TARGET_PARK_NAME:\n",
    "        raise ValueError(\"TARGET_PARK_NAME is not set in the .env file. Please specify which park to analyze.\")\n",
    "\n",
    "    if TARGET_PARK_NAME not in PARK_NAMES:\n",
    "        raise ValueError(\n",
    "            f\"The target park '{TARGET_PARK_NAME}' defined in .env is not found in 'config.yml'.\\n\"\n",
    "            f\"Available parks in config: {PARK_NAMES}\"\n",
    "        )\n",
    "\n",
    "    print(f\"üéØ Analysis will be performed for target park: '{TARGET_PARK_NAME}'\")\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Configuration loaded successfully from '{CONFIG_PATH}' for {len(PARK_NAMES)} park(s): {', '.join(PARK_NAMES)}.\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå CONFIGURATION ERROR: The '{CONFIG_PATH}' file was not found.\")\n",
    "    print(\n",
    "        \"Please check your .env file's PROJECT_ROOT setting, and ensure 'config.yml' exists at that location.\"\n",
    "    )\n",
    "    print(\n",
    "        \"If 'config.yml' is missing, copy 'config.example.yml' to 'config.yml' and fill in your park's details.\"\n",
    "    )\n",
    "except (yaml.YAMLError, ValueError) as e:\n",
    "    print(\n",
    "        f\"‚ùå CONFIGURATION ERROR: Could not parse '{CONFIG_PATH}'. Please check its format. Details: {e}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Plotting and Display Configuration ---\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# Set display options for better viewing in Jupyter\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "print(\"Plotting and display options set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522e0e5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6183609",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading Helper Function ---\n",
    "\n",
    "\n",
    "def load_park_specific_data(\n",
    "    file_path: str,\n",
    "    timestamp_col: str,\n",
    "    park_name_col: str,\n",
    "    required_data_cols: list[str],\n",
    "    target_park_name: str,\n",
    "    data_name: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads, validates, and filters data for a single specified park from a long-format CSV.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Absolute path to the CSV file.\n",
    "        timestamp_col (str): Name of the timestamp column.\n",
    "        park_name_col (str): Name of the park identifier column.\n",
    "        required_data_cols (list): List of required data column names.\n",
    "        target_park_name (str): The specific park to extract data for.\n",
    "        data_name (str): A descriptive name for the data (e.g., \"Production\").\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing only the data for the target park,\n",
    "                          with the park_name column removed. Returns an empty\n",
    "                          DataFrame on failure.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading {data_name} Data for '{target_park_name}' ---\")\n",
    "    print(f\"Attempting to load from: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load the full CSV\n",
    "        df = pd.read_csv(\n",
    "            file_path, parse_dates=[timestamp_col], index_col=timestamp_col\n",
    "        )\n",
    "\n",
    "        # 2. Basic Column Check\n",
    "        all_required_cols = required_data_cols + [park_name_col]\n",
    "        if not all(col in df.columns for col in all_required_cols):\n",
    "            missing = [col for col in all_required_cols if col not in df.columns]\n",
    "            raise ValueError(f\"Missing required columns in {data_name} CSV: {missing}\")\n",
    "\n",
    "        # 3. Data Cleaning and Validation\n",
    "        df.index = pd.to_datetime(df.index, utc=True)\n",
    "        df = df.dropna(subset=[park_name_col])\n",
    "        df[park_name_col] = df[park_name_col].astype(str)\n",
    "\n",
    "        # 4. Check if Target Park Exists in Data\n",
    "        if target_park_name not in df[park_name_col].unique():\n",
    "            raise ValueError(\n",
    "                f\"Target park '{target_park_name}' not found in the {data_name} file.\"\n",
    "            )\n",
    "\n",
    "        # 5. Filter for Target Park and Finalize\n",
    "        df_park = df[df[park_name_col] == target_park_name].copy()\n",
    "\n",
    "        # Drop the now-redundant park name column\n",
    "        df_park = df_park.drop(columns=[park_name_col])\n",
    "\n",
    "        df_park = df_park.sort_index()\n",
    "        print(f\"‚úÖ {data_name} data for '{target_park_name}' loaded successfully.\")\n",
    "        print(f\"   Shape of final DataFrame: {df_park.shape}\")\n",
    "        print(f\"   Time range: {df_park.index.min()} to {df_park.index.max()}\")\n",
    "        print(\"Sample:\")\n",
    "        print(df_park.sample(n=5))\n",
    "        return df_park\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå DATA ERROR: The {data_name} file was not found at: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AN UNEXPECTED ERROR OCCURRED during {data_name} data loading: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Helper function load_park_specific_data defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084d559",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 2.1 Hourly Production And Spot Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a38d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Production and Price Data ---\n",
    "\n",
    "# Define required column names for production data\n",
    "COL_TIMESTAMP = \"timestamp_utc\"\n",
    "COL_PARK_NAME = \"park_name\"\n",
    "PRODUCTION_DATA_COLS = [\"ac_export_kwh\", \"spot_price_eur_mwh\"]\n",
    "\n",
    "# Load the data for the target park using the helper function\n",
    "df_production = load_park_specific_data(\n",
    "    file_path=PRODUCTION_AND_PRICE_FILE_PATH,\n",
    "    timestamp_col=COL_TIMESTAMP,\n",
    "    park_name_col=COL_PARK_NAME,\n",
    "    required_data_cols=PRODUCTION_DATA_COLS,\n",
    "    target_park_name=TARGET_PARK_NAME,  # type: ignore\n",
    "    data_name=\"Production & Price\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45339e8",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 2.2 Load Hourly Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Crop Weather Data ---\n",
    "\n",
    "# Define required column names for weather data\n",
    "WEATHER_DATA_COLS = [\"temp_air_c\", \"wind_speed_m_s\", \"pressure_hpa\", \"ghi_w_m2\"]\n",
    "\n",
    "# Load the weather data for the target park using the helper function\n",
    "df_weather = load_park_specific_data(\n",
    "    file_path=WEATHER_FILE_PATH,\n",
    "    timestamp_col=COL_TIMESTAMP,\n",
    "    park_name_col=COL_PARK_NAME,\n",
    "    required_data_cols=WEATHER_DATA_COLS,\n",
    "    target_park_name=TARGET_PARK_NAME,  # type: ignore\n",
    "    data_name=\"Weather\",\n",
    ")\n",
    "\n",
    "# Post-processing: Crop the weather data to the production time range\n",
    "if not df_production.empty and not df_weather.empty:\n",
    "    start_time = df_production.index.min()\n",
    "    end_time = df_production.index.max()\n",
    "\n",
    "    original_rows = len(df_weather)\n",
    "    df_weather = df_weather.loc[start_time:end_time].copy()\n",
    "\n",
    "    print(f\"\\nWeather data cropped to production time range.\")\n",
    "    print(f\"   Original rows: {original_rows}, Cropped rows: {len(df_weather)}\")\n",
    "    print(f\"   New time range: {df_weather.index.min()} to {df_weather.index.max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
