{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b4f091",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Solar Irradiance From AC Export\n",
    "\n",
    "A Jupyter Notebook that does it's best to model and construct a historical solar irradiance time series from solar panel park's historical AC export data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb98ad",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5f3b9",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "\n",
    "# Standard Library Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"✅ Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd074bad",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 1.2 Configuration\n",
    "\n",
    "This project uses a two-step configuration process:\n",
    "\n",
    "1.  **Path Definition (`.env`):** This file defines the project's physical location (`PROJECT_ROOT`) and the name of the configuration file. This separation ensures the notebook is portable across different machines and environments.\n",
    "2.  **Parameter Definition (`config.yml`):** This file contains the physical and electrical parameters of your solar park(s), including sensitive information like GPS coordinates and detailed system specifications.\n",
    "\n",
    "**To get started:**\n",
    "\n",
    "1.  **Configure Paths:** Copy the template file `.env.example` to a new file named `.env`. Open `.env` and set the absolute path for the `PROJECT_ROOT` variable.\n",
    "2.  **Configure Parks:** Copy the example configuration file `config.example.yml` to `config.yml`. Open `config.yml` and replace the placeholder values with the details of your solar installation.\n",
    "\n",
    "The cell below loads the environment variables, resolves the final configuration path, and sets up the plotting environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cf6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define paths using environment variables\n",
    "PROJECT_ROOT_STR = os.getenv(\"PROJECT_ROOT\")\n",
    "CONFIG_FILENAME = os.getenv(\"CONFIG_FILENAME\", \"config.yml\")  # Fallback to config.yml\n",
    "\n",
    "if not PROJECT_ROOT_STR:\n",
    "    # If PROJECT_ROOT is not set in .env, assume the current working directory\n",
    "    PROJECT_ROOT_STR = os.getcwd()\n",
    "    print(\n",
    "        f\"⚠️ WARNING: PROJECT_ROOT not set in .env. Using current directory: {PROJECT_ROOT_STR}\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT_STR)\n",
    "CONFIG_PATH = PROJECT_ROOT / CONFIG_FILENAME\n",
    "\n",
    "print(f\"Project Root defined as: {PROJECT_ROOT}\")\n",
    "print(f\"Configuration file path: {CONFIG_PATH}\")\n",
    "\n",
    "try:\n",
    "    with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # Extract park configurations\n",
    "    PARK_CONFIGS = config.get(\"parks\", {})\n",
    "\n",
    "    if not PARK_CONFIGS:\n",
    "        raise ValueError(\n",
    "            \"No parks defined under the 'parks' key in the configuration file.\"\n",
    "        )\n",
    "\n",
    "    # Create a list of park names for easy iteration later\n",
    "    PARK_NAMES = list(PARK_CONFIGS.keys())\n",
    "\n",
    "    print(\n",
    "        f\"✅ Configuration loaded successfully from '{CONFIG_PATH}' for {len(PARK_NAMES)} park(s): {', '.join(PARK_NAMES)}.\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ CONFIGURATION ERROR: The '{CONFIG_PATH}' file was not found.\")\n",
    "    print(\n",
    "        \"Please check your .env file's PROJECT_ROOT setting, and ensure 'config.yml' exists at that location.\"\n",
    "    )\n",
    "    print(\n",
    "        \"If 'config.yml' is missing, copy 'config.example.yml' to 'config.yml' and fill in your park's details.\"\n",
    "    )\n",
    "except (yaml.YAMLError, ValueError) as e:\n",
    "    print(\n",
    "        f\"❌ CONFIGURATION ERROR: Could not parse '{CONFIG_PATH}'. Please check its format. Details: {e}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Plotting and Display Configuration ---\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# Set display options for better viewing in Jupyter\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "print(\"Plotting and display options set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522e0e5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084d559",
   "metadata": {},
   "source": [
    "### 2.1 Hourly Production And Spot Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a38d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Validation ---\n",
    "\n",
    "# Get the data path\n",
    "PRODUCTION_AND_PRICE_FILE_PATH = os.getenv(\n",
    "    \"PRODUCTION_AND_PRICE_FILE_PATH\",\n",
    "    \"/home/user/solar-irradiance-from-ac-export/production.csv\",\n",
    ")\n",
    "\n",
    "# Source CSV column names must follow a strict specification\n",
    "COL_TIMESTAMP = \"TimestampUTC\"\n",
    "COL_PARK_NAME = \"ParkName\"\n",
    "COL_EXPORT = \"AC_Export_kWh\"\n",
    "COL_PRICE = \"SpotPriceEUR_MWh\"\n",
    "\n",
    "REQUIRED_COLUMNS = [COL_TIMESTAMP, COL_PARK_NAME, COL_EXPORT, COL_PRICE]\n",
    "\n",
    "print(f\"Attempting to load data from: {PRODUCTION_AND_PRICE_FILE_PATH}\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the CSV\n",
    "    df_raw = pd.read_csv(\n",
    "        PRODUCTION_AND_PRICE_FILE_PATH,\n",
    "        parse_dates=[COL_TIMESTAMP],\n",
    "        # Ensure the timestamp column is treated as the index upon loading\n",
    "        index_col=COL_TIMESTAMP,\n",
    "    )\n",
    "\n",
    "    # 2. Basic Column Check\n",
    "    if not all(\n",
    "        col in df_raw.columns for col in REQUIRED_COLUMNS[1:]\n",
    "    ):  # Check all except the index column\n",
    "        missing = [col for col in REQUIRED_COLUMNS[1:] if col not in df_raw.columns]\n",
    "        raise ValueError(f\"Missing required columns in CSV: {missing}\")\n",
    "\n",
    "    # 3. Data Cleaning and Preparation\n",
    "\n",
    "    # Ensure the index is a proper DatetimeIndex and set to UTC\n",
    "    df_raw.index = pd.to_datetime(df_raw.index, utc=True)\n",
    "\n",
    "    # Filter out any rows where the park name is missing or NaN\n",
    "    df_raw = df_raw.dropna(subset=[COL_PARK_NAME])\n",
    "\n",
    "    # Convert ParkName column to string type for reliable comparison\n",
    "    df_raw[COL_PARK_NAME] = df_raw[COL_PARK_NAME].astype(str)\n",
    "\n",
    "    # 4. Park Name Validation\n",
    "\n",
    "    # Identify unique parks in the loaded data\n",
    "    data_parks = set(df_raw[COL_PARK_NAME].unique())\n",
    "\n",
    "    # Identify parks defined in the YAML configuration\n",
    "    config_parks = set(PARK_NAMES)\n",
    "\n",
    "    # Check for parks present in data but missing in config\n",
    "    missing_config_parks = data_parks - config_parks\n",
    "\n",
    "    if missing_config_parks:\n",
    "        print(\n",
    "            \"⚠️ WARNING: The following parks found in the data are missing from 'config.yml':\"\n",
    "        )\n",
    "        for park in missing_config_parks:\n",
    "            print(f\"  - {park}\")\n",
    "        print(\n",
    "            \"Please update 'config.yml' with parameters for these parks or ensure names match.\"\n",
    "        )\n",
    "\n",
    "    # Check for parks present in config but missing in data (less critical, but good to know)\n",
    "    missing_data_parks = config_parks - data_parks\n",
    "    if missing_data_parks:\n",
    "        print(\n",
    "            \"ℹ️ INFO: The following parks defined in 'config.yml' were not found in the data:\"\n",
    "        )\n",
    "        for park in missing_data_parks:\n",
    "            print(f\"  - {park}\")\n",
    "\n",
    "    # 5. Final Filtering and Assignment\n",
    "\n",
    "    # Filter the DataFrame to only include parks that are defined in the YAML file\n",
    "    df_production = df_raw[df_raw[COL_PARK_NAME].isin(config_parks)].copy()\n",
    "\n",
    "    if df_production.empty:\n",
    "        print(\n",
    "            \"❌ ERROR: The resulting production DataFrame is empty. Check park names and data file path.\"\n",
    "        )\n",
    "    else:\n",
    "        # Final check: Ensure the data is hourly and sort by time\n",
    "        df_production = df_production.sort_index()\n",
    "\n",
    "        print(f\"✅ Data loaded and validated successfully.\")\n",
    "        print(f\"   Shape of final DataFrame: {df_production.shape}\")\n",
    "        print(\n",
    "            f\"   Time range: {df_production.index.min()} to {df_production.index.max()}\"\n",
    "        )\n",
    "        print(\"Sample:\")\n",
    "        print(df_production.sample(n=5))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"❌ DATA ERROR: The data file was not found at the specified path: {PRODUCTION_AND_PRICE_FILE_PATH}\"\n",
    "    )\n",
    "    print(\n",
    "        \"Please check the 'PRODUCTION_AND_PRICE_FILE_PATH' variable in your '.env' file.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"❌ AN UNEXPECTED ERROR OCCURRED during data loading: {e}\")\n",
    "    df_production = pd.DataFrame()  # Ensure df_production exists even on failure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
